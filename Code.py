ect # -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TPY330pEbXwm5srp8ethnNznX8hiMnPE
"""

# Importing the dependencies

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# loading the dataset to a Pandas DataFrame

credit_card_data = pd.read_csv('/content/creditcard.csv')

# printing first 5 rows

credit_card_data.head()

credit_card_data.tail()

# dataset information

credit_card_data.info()

# checking the number of missing values in each column
credit_card_data.isnull().sum()

# distribution of legit transactions & fraudulent transactions
credit_card_data['Class'].value_counts()

# this dataset is very imbalanced
# 0 represents normal transactions
# 1 represents fraudulent transactions

# separating data for analysis
legit = credit_card_data[credit_card_data.Class == 0]
fraud = credit_card_data[credit_card_data.Class == 1]

print(legit.shape)
print(fraud.shape)

# getting the statistical measures of the data
legit.Amount.describe()

fraud.Amount.describe()

# compare the values for both the transactions
credit_card_data.groupby('Class').mean()

# under sampling
# sample dataset containing similar distribution of normal transaction and fraudulent transactions
# number of fraudulent transaction = 492

legit_sample = legit.sample(n = 492)

# concatenating the two data frames

new_dataset = pd.concat([legit_sample, fraud], axis = 0) # axis=0 means adding the newly concatenating columns beneath the previous column and not aside them

new_dataset.head()

new_dataset.tail()

new_dataset['Class'].value_counts()

new_dataset.groupby('Class').mean()

"""Splitting the data into features and targets(0, 1)"""

x = new_dataset.drop(columns ='Class', axis=1)
y = new_dataset['Class']

print(x)

print(y)

"""Split the data into training data and Testing data"""

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=2)

print(x.shape, x_train.shape, x_test.shape)

"""Logistic regression

Model Training
"""

model = LogisticRegression()

# training the logistic regression model with training data
model.fit(x_train, y_train)

# evaluating the performance of the model
# finding the accuracy score

# accuracy on training data
x_train_prediction = model.predict(x_train)
training_data_Accuracy = accuracy_score(x_train_prediction, y_train)

print('accuracy on training data: ', training_data_Accuracy)

x_test_prediction = model.predict(x_test)
test_data_accuracy = accuracy_score(x_test_prediction, y_test)

print('accuracy score on test data: ', test_data_accuracy)
